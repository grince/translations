„Zusammenleben in der digitalen Gesellschaft – Teilhabe ermöglichen, Sicherheit gewährleisten, Freiheit bewahren“

Rede des Bundesministers der Justiz und für Verbraucherschutz Heiko Maas „Zusammenleben in der digitalen Gesellschaft – Teilhabe ermöglichen, Sicherheit gewährleisten, Freiheit bewahren“ bei der Konferenz „Digitales Leben –Vernetzt. Vermessen. Verkauft? #Werte #Algorithmen #IoT“ am 3. Juli 2017 in Berlin

ES GILT DAS GESPROCHENE WORT!

Meine sehr geehrten Damen und Herren,
verehrte Gäste,

ich begrüße Sie alle vielmals in diesen beeindruckenden historischen Räumen.

Vor fast 150 Jahren wurde hier das „Reichspostministerium“ gegründet.

Briefkästen, Telefone und Postkutschen sind die Exponate der Kommunikation in der Vergangenheit.

Ich frage mich, wie die Kuratoren es dereinst schaffen werden, dem neugierigen Besucher einen Algorithmus zu präsentieren. Dafür wird man Wege und Möglichkeiten finden.

Im digitalen Zeitalter ist Kommunikation zu einem Phänomen geworden, das kaum noch sichtbar und greifbar ist. Trotzdem bestimmt die digitale Kommunikation immer mehr unseren kompletten Alltag – im Beruf, im Verkehr, im Privatleben und auch in den eigenen vier Wänden.

Nicht nur Ausstellungsmacher stehen vor dem Problem, digitale Phänomene sichtbar und greifbar zu machen, sondern wir alle, die wir uns damit befassen.

Mangelnde Transparenz ist ein Problem für uns alle. Wir wissen zwar, dass im Internet unzählige persönliche Daten transportiert werden, dass man sie vernetzen und auswerten kann, aber die Einzelheiten bleiben oft völlig unsichtbar.

– Wer weiß schon, welche Daten sein eigenes Smartphone täglich mit wem austauscht?

– Wer rechnet damit, dass selbst der Rhythmus, mit dem wir eine Tastatur bedienen, Auskunft geben kann, in welcher Konsumlaune wir sind?

– Und wer ahnt schon, dass die Fotos, die man auf Instagram veröffentlicht, zur Kalkulation unseres Gemütszustandes ausgewertet werden können?

Meine Damen und Herren,
wenn Daten, die aus unserem Verhalten gewonnen werden, so weitreichende Schlussfolgerungen erlauben, wäre es sicherlich sinnvoll, Licht in dieses digitale Dunkel bringen.

Ich will im Folgenden auf drei Handlungsfelder eingehen, die wir in der Öffentlichkeit und in der Politik beackern müssen, wenn das Zusammenleben in der digitalen Gesellschaft ein gedeihliches sein soll. Es geht darum, die Werte, die unser Zusammenleben in der analogen Welt prägen, auch im digitalen Zeitalter zu wahren. Es geht um nicht mehr, aber auch nicht weniger als Teilhabe, Freiheit und Sicherheit.

– Wir brauchen eine gleichberechtigte Teilhabe am gesellschaftlichen Leben – ohne Diskriminierungen, sondern mit gleichen Chancen für alle.

– Wir müssen die Selbstbestimmung und Handlungsfreiheit des Einzelnen bewahren; Menschen dürfen nicht von Technik beherrscht werden.

– Und wir müssen dafür Sorge tragen, dass die Verantwortlichkeiten für die Sicherheit im Netz klarer werden und die Durchsetzung des Rechts auch im Internet gewährleistet ist.

Meine Damen und Herren,
wir alle sind heute vernetzt. Wir alle werden in der digitalen Welt vermessen. Und wir alle müssen aufpassen, dass wir bei allen großartigen Chancen, die das Internet bietet, nicht am Ende genau die Werte verkaufen und opfern, die für eine freiheitliche und demokratische Gesellschaft essenziell sind.

Das fundamental Neue an dieser vierten industriellen Revolution ist, dass bisher gültige Grenzen zwischen privat und öffentlich, zwischen „mein“ und „dein“, ja selbst zwischen Mensch und Maschine verschwimmen.

Die immer stärkere digitale Vernetzung führt dazu, dass am Ende alles mit allem kommuniziert und man die Welt nicht mehr in „online“ und „offline“ aufteilen kann.

Schon eine Autofahrt mit dem Navigationssystem oder ein Waldspaziergang mit Smartphone am Ohr macht diese Verflechtung deutlich.

Der Philosoph Luciano Floridi, der an der Universität Oxford lehrt und arbeitet, nennt diese digitale Lebensform „On-life“.
„Onlife“ ist eine Sphäre, in der sowohl Menschen mit Maschinen,
Maschinen mit Maschinen,
und natürlich auch noch Menschen mit Menschen interagieren.

Es geht nicht darum, diese Entwicklung zu beklagen – ganz im Gegenteil. Es geht auch nicht um Kultur-Pessimismus oder Technik-Feindlichkeit.

Entscheidend ist vielmehr, dass unsere Gesellschaft diskutiert, wie wir Werte und Regeln, die für unser Zusammenleben wichtig sind, auch in der „Onlife“-Welt erhalten.

Meine Damen und Herren,
deshalb zunächst zur Frage der gesellschaftlichen Teilhabe:

Wie kann auch in der digitalen Welt eine gleichberechtigte Teilhabe am gesellschaftlichen Leben ohne Diskriminierungen, sondern mit gleichen Chancen für alle ermöglicht werden?

Wie kann sich der Sozialstaat davor schützen, dass die Schwächeren in unserer Gesellschaft bei der Digitalisierung auf der Strecke bleiben und von gesellschaftlicher Teilhabe ausgeschlossen werden?

Wir produzieren täglich unzählige Daten und rund um die Uhr hinterlassen wir überall Datenspuren. Die Menge der Daten ist so groß wie nie zuvor, es werden in der Zukunft auch noch mehr werden.

Wenn diese Big Data digital ausgewertet werden, kann es schnell Gewinner und Verlierer geben. Wenn soziale oder wirtschaftliche Scoring-Verfahren eingesetzt werden, kann die gefährliche Gleichung lauten:

Positive Daten bedeuten Vorteile und Teilhabe – negative Daten Nachteile und Ausgrenzung.

Und gar keine Daten können in der digitalen Gesellschaft einer faktischen Nichtexistenz gleichkommen. Wenn zum Beispiel die Bonität von Menschen anhand von Posts bei Facebook und ihrem dortigen „Freundeskreis“ bewertet wird, kann die Abwesenheit von einem Facebook-Profil schnell zu einer ökonomischen Diskriminierung führen.

Wenn Daten aus der Vergangenheit über Teilhabe-Chancen in der Zukunft bestimmen, ist das nicht unbedenklich.

Selbstlernende Algorithmen versuchen das Verhalten von Menschen mit immer höherer Genauigkeit vorherzusagen. Schon heute beeinflussen Algorithmen viele Entscheidungen – sowohl im Geschäftsleben als auch politisch und sozial:

– Der Preis eines Flugtickets, die Kreditwürdigkeit eines Verbrauchers oder der Zugang eines Kunden zu bestimmten Versicherungstarifen werden immer öfter individuell von Algorithmen bestimmt. Und bei bestimmten Kundenhotlines werden angeblich auch nur noch Anrufer durchgestellt, die von einem Algorithmus als wohlhabend eingestuft werden.

Besonders schwierig werden digitale Scoring-Verfahren, wenn sie nicht nur kommerzielle, sondern soziale oder politische Ziele verfolgen:

– In den USA werden Bewerbungen durch Algorithmen vorsortiert, und die Justiz lässt mancherorts sogar Rückfallwahrscheinlichkeiten von Straftätern von Algorithmen prognostizieren.

– In China werden in ausgewählten Regionen für jeden Bürger rund 5.000 verschiedene Behördendaten digital zusammengeführt, um seine „soziale Zuverlässigkeit“ zu errechnen. Für die Angepassten gibt es Privilegien, bei abweichendem Verhalten gibt es Sanktionen, vom Ausreiseverbot bis hin zu Bildungsbeschränkungen für die Kinder.

Meine Damen und Herren,
alle diese Verfahren reduzieren die Menschen auf ihre Vergangenheit und können wichtige Chancen auf einen Neustart in der Zukunft verbauen.

Wir sollten auch mit unserem Glauben an die Objektivität der Technik vorsichtig sein – Algorithmen sind nur so gut wie diejenigen, die sie programmiert haben, und die Datenbasis, mit der sie gelernt haben. Fehler, die dort stattfinden, werden sich in ungeahnter Weise vervielfältigen.

In Australien hat die Regierung vergangenes Jahr ein Experiment mit algorithmischer Entscheidungsfindung gestartet. Die Steuerbehörden haben ihre Bescheide ausschließlich mit Hilfe von Datenabgleichen erstellt:
– voll automatisiert,
– ohne Anhörung der Betroffenen
– ohne Offenlegung der Entscheidungskriterien.

Das Ergebnis war, dass auf Millionen Menschen massive Steuerforderungen zukamen, ohne dass überhaupt klar war, warum.
Die australischen Medien nannten diese vom Algorithmus ermittelten angeblichen Schulden denn auch „Robo-Debt“ – „Roboter-Schulden“.

Jenseits des Datenschutzes hat der Einsatz von Algorithmen auch massive gesellschaftliche Effekte. So können soziale Verhältnisse zementiert werden, wenn die Daten, die ein Algorithmus analysiert, bereits selbst Diskriminierungen enthalten. Soziale Ungleichheit kann dann reproduziert und damit im Ergebnis auch verfestigt werden.

In den USA wird zum Beispiel die automatisierte Gesichtserkennung als Beweismittel vor Gericht verwandt. Wissenschaftler haben festgestellt, dass ein Afro-Amerikaner, der vor Gericht steht, bei dieser vermeintlich ganz objektiven Technik einem deutlich höheren Risiko ausgesetzt ist, fälschlicherweise verurteilt zu werden, als ein Nicht-Afro-Amerikaner.

Warum? Weil diese Gesichtserkennungsprogramme vor allem mit weißen Testpersonen trainiert werden und deshalb deutlich differenzierendere Ergebnisse bei Weißen liefern, während die Quote falscher Treffer bei Afro-Amerikanern sehr viel höher ist.

Das war ein Beispiel mit besonders drastischen Konsequenzen, aber es gibt auch Diskriminierungen, die weitaus weniger augenscheinlich sind.

Wenn heute etwa bestimmte Online-Händler in bestimmte Postleitzahl-Bereiche nicht mehr ausliefern, weil dort die Betrugsfälle besonders hoch sind, dann wird der rechtstreue Besteller in Mitverantwortung genommen und wegen seiner Postleitzahl diskriminiert.

Meine Damen und Herren,
letztlich sind Algorithmen bloß Werkzeuge. Nicht jedes Werkzeug aber ist für jede Aufgabe geeignet. Je sensibler ein Bereich ist, in dem ein bestimmtes Werkzeug eingesetzt werden soll, desto wichtiger ist es, die Fehleranfälligkeit und Aussagekraft des Algorithmus zu prüfen und zu diskutieren.

Im Bereich der Polizeiarbeit oder Strafverfolgung können die Folgen von algorithmischen Fehlern für die Betroffenen verheerend sein. Aber es geht auch um das soziale Zusammenleben.

Seit mehr als zehn Jahren haben wir in Deutschland das AGG – das Antidiskriminierungsgesetz.

Wer an der Tür zum Club vom Türsteher wegen seiner Hautfarbe abgewiesen wird, wer wegen einer Behinderung als Hotelgast unerwünscht ist – der kann sich mit diesem Gesetz gegen diese Diskriminierungen wehren.

Ich glaube, ein digitales AGG, ein digitales Antidiskriminierungsgesetz könnte hilfreich sein – gegen digitale Diskriminierung und für vorurteilsfreies Programmieren.

Technischer Fortschritt darf eben nicht zu gesellschaftlichem Rückschritt führen, und deshalb wäre ein Ordnungsrahmen nötig, der viel Raum für Innovationen bietet, der aber genauso den Einsatz von diskriminierenden Algorithmen verhindert.

Meine Damen und Herren,
in der schönen neuen Welt der Algorithmen müssen wir auch die Selbstbestimmung bewahren.

Die Grundfrage lautet hier: Wie schützen wir in Zeiten der Digitalisierung die Selbstbestimmung und die Handlungsfreiheit des Einzelnen? Wie verhindern wir, dass Menschen nicht allein der Technik unterworfen werden?

Vielleicht kennen Sie die englische Comedy-Serie „Little Britain“.

Da gibt es einen Sketch mit dem Titel „Computer says No“.

Verschiedene Bürger besuchen ein Reisebüro, sind bei der Bank oder bei der Anmeldung im Krankenhaus.

Ihre Anliegen werden überall von Mitarbeitern aufgenommen und in den Computer eingegeben. Aber was immer sie wollen, sie bekommen überall die gleiche Auskunft: „Computer says No“.

Warum und wieso entschieden wurde, bleibt das Geheimnis des Algorithmus. Eine Begründung gibt es nichts. Lediglich Mitarbeiter, die nur wiederholen können: „Computer says No“

Was als Comedy lustig daherkommt, verweist auf ein ernstes Problem der digitalen Welt: Bis zu welchem Grad sind wir bereit, unsere Handlungsfreiheit durch Algorithmen beschneiden zu lassen? Und wie schaffen wir die Transparenz, die Voraussetzung für jede Selbstbestimmung ist?

Wie weit ist es mit diesen Maximen eigentlich noch her, wenn etwa unser Such- und Leseverhalten im Netz so ausgewertet wird, das uns ständig Vorschläge gemacht werden, die auf unser bisheriges Verhalten abgestimmt sind?

Diesen gleichen Effekt der permanenten Selbstbestätigung fördern soziale Netzwerke, wenn einzelne Botschaften durch Algorithmen sortiert, personalisiert oder gefiltert werden.

Indem Algorithmen menschliches Verhalten auf vorbestimmte Bahnen lenken, können sie die Selbstbestimmung und Handlungsfreiheit des Einzelnen durchaus auch einschränken.

Früher hieß das Tunnelblick. Heute sind es die „Echokammer“ und die „Filter-Blase“, die dafür sorgen, dass wir oftmals nur noch auf Positionen treffen, die uns in der eigenen Meinung bestärken – egal wie absurd die im Einzelfall auch sein mag. Selbst die Anhänger der „Flat Earth“-Theorie bekommen permanent neue Belege aus dem Netz, die ihre Theorie bestätigen, dass die Erde tatsächlich eine Scheibe ist.

Wenn Sie eine Zeitung oder Zeitschrift von vorne bis hinten durchblättern, stoßen Sie immer wieder auf Themen und Thesen, die sie bislang nicht kannten und nun für sich entdecken können, ohne nach ihnen gesucht zu haben.

Solche Neuentdeckungen verhindern die Echokammern und Filter-Blasen im Netz: Überraschungen, Irritationen, abweichende Meinungen werden ausgeblendet, damit sich der Nutzer in seiner eitlen Selbstbespiegelung und Selbstbejahung sogar noch sonnen kann.

Diese Form der Weltflucht und des Verzichts auf Selbstbestimmung ist für das Zusammenleben und den Zusammenhalt in einer Gesellschaft durchaus kontraproduktiv.

Es ist ja nicht so, dass in der analogen Welt die Menschen immer parallel die FAZ und das „Neue Deutschland“ lesen, um ihren Horizont zu weiten. Aber der Unterschied ist, dass in der analogen Welt die Ausrichtungen dieser Blätter transparent sind und die Entscheidungen für das eine oder andere Medium bewusst und selbstbestimmt getroffen werden.

Wenn aber unter dem Mantel der technischen Neutralität und Objektivität Trefferlisten und die Anzeige von Nachrichten und Postings politisch manipuliert werden, dann bleibt die demokratische Selbstbestimmung auf der Strecke.

Ein Transparenzgebot für Algorithmen wäre hilfreich,
– damit Nutzerinnen und Nutzer verlässlich einschätzen können, ob das Netz versucht, sie zu beeinflussen,
– und damit sie selbstbestimmt entscheiden können, welche Filter und Personalisierungen sie in der digitalen Welt akzeptieren wollen und welche nicht.

„Computer says No“ – das passt nicht zu einem freiheitlichen Rechtsstaat.

Im Rechtsstaat sind alle Entscheidungen begründungspflichtig. Denn nur so kann überprüft werden, ob die Grundlagen, auf denen sie getroffen wurden, richtig, rechtmäßig und auch verhältnismäßig sind. Eine solche Überprüfbarkeit brauchen wir auch, wenn Algorithmen Entscheidungen vorbereiten.

Auch im digitalen Raum muss sich der freie gesellschaftliche Diskurs vollziehen können. Und gerade die politische Willensbildung muss frei bleiben von digitaler Manipulation aus dem Verborgenen heraus.

Meine Damen und Herren,
es bleibt der letzte Aspekt der Sicherheit.

Wie können wir gewährleisten, dass die digitalen Prozesse und Produkte sicher sind, und dafür sorgen, dass geltendes Recht im Netz eingehalten wird? Es geht um digitale Produktsicherheit, aber auch um Rechtssicherheit.

Wenn digitale Produkte und Prozesse Sicherheitslücken aufweisen, dann müssen die Verantwortlichkeiten zwischen Herstellern, Dienstleistern und Verbrauchern klarer sein, als es bisher der Fall ist. Denn die Risiken müssen fair verteilt sein.

Erst vor wenigen Tagen mussten Unternehmen und Behörden auf der ganzen Welt einen massiven Cyberangriff mit Schadprogrammen auf ihre Netzwerke abwehren.

Und je mehr alltägliche Geräte im sogenannten „Internet der Dinge“ digital miteinander kommunizieren, desto höher sind die Sicherheitsrisiken, derer sich viele Nutzerinnen und Nutzer noch gar nicht bewusst sind.

Um europaweit geltende Vorschriften zur IT-Sicherheit, die verpflichtende Mindestanforderungen definieren, werden wir nicht herumkommen.

Außerdem könnte durch die Einführung eines freiwilligen Gütesiegels für internetfähige Produkte mehr Transparenz über die jeweiligen Sicherheitseigenschaften hergestellt werden.

Risikoverteilung ist immer eine Frage der Verteilung von Verantwortung. Aber Verantwortung kann man nur für Risiken tragen, die man kennen und beherrschen kann. Sicherheitslücken bei der Programmierung sind dem Zugriff des Durchschnittsverbrauchers völlig entzogen, und deshalb ist es nicht fair, wenn die Folgen solcher Sicherheitslücken einseitig auf den Verbraucher abgewälzt werden.

Meine Damen und Herren,
neben der Produktsicherheit muss es auch die Sicherheit geben, dass das geltende Recht auch im Internet eingehalten wird. Schnelle Überprüfungs- und Abhilfemöglichkeiten, eine effektive Rechtsdurchsetzung sind zwingende Voraussetzung, damit die Menschen Vertrauen in die digitale Welt fassen und ein Leben „onlife“ tatsächlich auch Zukunft hat.

Das Internet darf kein rechtsfreier Raum sein. Und es darf auch keinen rechtsschutzfreien Raum geben.

Meine Damen und Herren,
unsere Gesellschaft darf ihren Anspruch, die Digitalisierung zu gestalten, nicht aufgeben und vor den kommerziellen Interessen der globalen Internet-Riesen nicht die Segel streichen.

Die Digitalisierung ist eine großartige und faszinierende Entwicklung. Ich wollte in keiner anderen Epoche leben als im digitalen Zeitalter.

Aber wir müssen gemeinsam dafür Sorge tragen, dass Werte, die schon unsere Vorfahren erstritten und erkämpft haben, nicht leichtfertig untergraben werden.

Gleichheit und Freiheit – das sind die Werte, um die es im Wesentlichen geht. Und Transparenz ist der Garant dafür, um Diskriminierungen zu verhindern und Selbstbestimmung zu sichern.

Deshalb brauchen wir mehr Transparenz von Algorithmen. Wir brauchen auch eine Rechtsdurchsetzung, Aufsicht und die Kontrolle von Transparenz.

Wir brauchen auch mehr wissenschaftliche Expertise, denn wie soll die Gesellschaft der Technik Regeln setzen, wenn der Sachverstand dafür nur in betroffenen Unternehmen vorhanden ist? Deshalb sollte die nächste Bundesregierung eine „Digital-Agentur“ gründen, um im Austausch mit Wissenschaft, Wirtschaft und Verbrauchern mehr Expertise zu erlangen – über Algorithmen, über das Internet der Dinge und das Leben in der digitalen Welt.

Die oberste Maxime unseres Zusammenlebens ist und bleibt die Würde eines jeden Menschen. „Computer says No“ – das ist mit dieser Maxime nicht vereinbar. Denn zur Menschenwürde im digitalen Zeitalter gehört vor allem, dass niemals ein Mensch zum bloßen Objekt von Technik oder auch Algorithmen werden darf.

Herzlichen Dank!
